{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis with Spark.SQL: Transforming\n",
    "* **Author**: Jose Rodriguez (@Cyb3rPandah)\n",
    "* **Project**: Infosec Jupyter Book\n",
    "* **Public Organization**: [Open Threat Research](https://github.com/OTRF)\n",
    "* **License**: [Creative Commons Attribution-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-sa/4.0/)\n",
    "* **Reference**: https://spark.apache.org/docs/latest/api/python/pyspark.sql.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating SQL view from Mordor APT29 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Spark_Data_Analysis\") \\\n",
    "    .config(\"spark.sql.caseSensitive\",\"True\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expose the dataframe as a SQL view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "apt29Json = '../datasets/apt29_evals_day1_manual_2020-05-01225525.json'\n",
    "\n",
    "apt29Df = spark.read.json(apt29Json)\n",
    "\n",
    "apt29Df.createOrReplaceTempView('apt29')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming data with Spark Built-In functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert ProcessId (String) to Integer format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataframe has 447 records!!\n",
      "root\n",
      " |-- ProcessId: string (nullable = true)\n",
      " |-- IntegerProcessId: integer (nullable = true)\n",
      "\n",
      "+---------+----------------+\n",
      "|ProcessId|IntegerProcessId|\n",
      "+---------+----------------+\n",
      "|8524     |8524            |\n",
      "|5156     |5156            |\n",
      "|2772     |2772            |\n",
      "|5944     |5944            |\n",
      "|4152     |4152            |\n",
      "+---------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "IntegerProcessId = spark.sql(\n",
    "'''\n",
    "SELECT ProcessId, cast(ProcessId as Integer) as IntegerProcessId\n",
    "FROM apt29\n",
    "WHERE lower(Channel) LIKE '%sysmon%'\n",
    "    AND EventID = 1\n",
    "''')\n",
    "\n",
    "print('This dataframe has {} records!!'.format(IntegerProcessId.count()))\n",
    "IntegerProcessId.printSchema()\n",
    "IntegerProcessId.show(n = 5, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert ProcessId (Integer) to Hexadecimal format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataframe has 447 records!!\n",
      "root\n",
      " |-- ProcessId: string (nullable = true)\n",
      " |-- HexadecimalProcessId: string (nullable = true)\n",
      "\n",
      "+---------+--------------------+\n",
      "|ProcessId|HexadecimalProcessId|\n",
      "+---------+--------------------+\n",
      "|8524     |214C                |\n",
      "|5156     |1424                |\n",
      "|2772     |AD4                 |\n",
      "|5944     |1738                |\n",
      "|4152     |1038                |\n",
      "+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HexadecimalProcessId = spark.sql(\n",
    "'''\n",
    "SELECT ProcessId, hex(cast(ProcessId as Integer)) as HexadecimalProcessId\n",
    "FROM apt29\n",
    "WHERE lower(Channel) LIKE '%sysmon%'\n",
    "    AND EventID = 1\n",
    "''')\n",
    "\n",
    "print('This dataframe has {} records!!'.format(HexadecimalProcessId.count()))\n",
    "HexadecimalProcessId.printSchema()\n",
    "HexadecimalProcessId.show(n = 5, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming data with Spark User Defined Functions (UDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the number of characters of Commad Line values in Sysmon 1 (Process Creation) events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LenCommand(value):\n",
    "    Length = len(value)\n",
    "    return Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import **pyspark.sql.types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Register **UDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.LenCommand(value)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register(\"LengthCommand\", LenCommand, IntegerType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use **UDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataframe has 447 records!!\n",
      "root\n",
      " |-- CommandLine: string (nullable = true)\n",
      " |-- LengthCommandLine: integer (nullable = true)\n",
      "\n",
      "+--------------------------------------------------------------------------------+-----------------+\n",
      "|                                                                     CommandLine|LengthCommandLine|\n",
      "+--------------------------------------------------------------------------------+-----------------+\n",
      "|                                     \"C:\\ProgramData\\victim\\â€®cod.3aka3.scr\" /S|               43|\n",
      "|\\\\?\\C:\\windows\\system32\\conhost.exe --headless --width 80 --height 25 --signa...|               99|\n",
      "|                                                   \"C:\\windows\\system32\\cmd.exe\"|               29|\n",
      "|                                                                      powershell|               10|\n",
      "|\"C:\\windows\\system32\\SearchProtocolHost.exe\" Global\\UsGthrFltPipeMssGthrPipe6...|              308|\n",
      "+--------------------------------------------------------------------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "commandLine = spark.sql(\n",
    "'''\n",
    "SELECT CommandLine, LengthCommand(CommandLine) as LengthCommandLine\n",
    "FROM apt29\n",
    "WHERE Channel LIKE '%Sysmon%'\n",
    "    AND EventID = 1\n",
    "''')\n",
    "\n",
    "print('This dataframe has {} records!!'.format(commandLine.count()))\n",
    "commandLine.printSchema()\n",
    "commandLine.show(n = 5, truncate = 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you! I hope you enjoyed it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark_Python3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}